{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y45yhDufI5Uo"
      },
      "source": [
        "# **RNN**\n",
        "A recurrent neural network (RNN) is a class of artificial neural network where connections between units form a directed cycle. This creates an internal state of the network which allows it to exhibit dynamic temporal behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55i8db8uI5U3"
      },
      "source": [
        "IMDB sentiment classification task\n",
        "\n",
        "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. IMDB provided a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided.\n",
        "\n",
        "You can download the dataset from http://ai.stanford.edu/~amaas/data/sentiment/  or you can directly use \n",
        "\" from keras.datasets import imdb \" to import the dataset.\n",
        "\n",
        "Few points to be noted:\n",
        "Modules like SimpleRNN, LSTM, Activation layers, Dense layers, Dropout can be directly used from keras\n",
        "For preprocessing, you can use required "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SozhvLNkI5U6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ]
        }
      ],
      "source": [
        "#load the imdb dataset \n",
        "from keras.datasets import imdb\n",
        "\n",
        "vocabulary_size = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NrilwfurI5VA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---review---\n",
            "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32])\n",
            " list([1, 194, 1153, 194, 2, 78, 228, 5, 6, 1463, 4369, 2, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 2, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 2, 2, 349, 2637, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 2, 5, 2, 656, 245, 2350, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 2, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 2, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " ...\n",
            " list([1, 11, 6, 230, 245, 2, 9, 6, 1225, 446, 2, 45, 2174, 84, 2, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 2, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 2, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 2, 5, 4241, 18, 4, 2, 2, 250, 11, 1818, 2, 4, 4217, 2, 747, 1115, 372, 1890, 1006, 541, 2, 7, 4, 59, 2, 4, 3586, 2])\n",
            " list([1, 1446, 2, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 2, 112, 2, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 2, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23])\n",
            " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 2, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 2, 2, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 2, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 2, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 2, 2, 21, 60, 27, 239, 9, 43, 2, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])]\n",
            "---label---\n",
            "[1 0 0 ... 0 1 0]\n",
            "---review with words---\n",
            "<generator object <genexpr> at 0x7fed2b1092e0>\n",
            "---label---\n",
            "[1 0 0 ... 0 1 0]\n"
          ]
        }
      ],
      "source": [
        "#the review is stored as a sequence of integers. \n",
        "# These are word IDs that have been pre-assigned to individual words, and the label is an integer\n",
        "\n",
        "print('---review---')\n",
        "print(X_train)\n",
        "print('---label---')\n",
        "print(y_train)\n",
        "\n",
        "# to get the actual review\n",
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print(id2word.get(i, ' ') for i in X_train)\n",
        "print('---label---')\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "h6upWxEWI5VC"
      },
      "outputs": [],
      "source": [
        "#pad sequences (write your code here)\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=200)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-RcCOpeNI5VF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2021-12-07 15:01:38.468162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2021-12-07 15:01:38.468593: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2021-12-07 15:01:38.468648: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pc): /proc/driver/nvidia/version does not exist\n",
            "2021-12-07 15:01:38.470508: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "#design a RNN model (write your code)\n",
        "\n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout,SimpleRNN,Activation\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 32, input_length=200) )\n",
        "model.add(SimpleRNN(32,input_shape = (vocabulary_size,100), return_sequences=False,activation=\"relu\") )\n",
        "model.add(Dense(1))\n",
        "model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "InQ2TED3I5VI"
      },
      "outputs": [],
      "source": [
        "#train and evaluate your model\n",
        "#choose your loss function and optimizer and mention the reason to choose that particular loss function and optimizer\n",
        "# use accuracy as the evaluation metric\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "q6A9Q0xmI5VJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 0.5443 - accuracy: 0.7202 - val_loss: 0.4342 - val_accuracy: 0.8064\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 24s 30ms/step - loss: 0.3696 - accuracy: 0.8407 - val_loss: 0.4219 - val_accuracy: 0.8309\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 22s 28ms/step - loss: 0.3853 - accuracy: 0.8434 - val_loss: 0.3566 - val_accuracy: 0.8463\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 23s 30ms/step - loss: 0.2576 - accuracy: 0.8959 - val_loss: 0.3294 - val_accuracy: 0.8602\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed2b100a90>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size = 32\n",
        "num_epochs = 4\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=num_epochs, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YTXG__EmI5VM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3294 - accuracy: 0.8602\n",
            "Loss: 0.32937532663345337 , accuracy:0.8601599931716919\n"
          ]
        }
      ],
      "source": [
        "#evaluate the model using model.evaluate()\n",
        "scores_rnn = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {scores_rnn[0]} , accuracy:{scores_rnn[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1uSo8DgI5VN"
      },
      "source": [
        "# **LSTM**\n",
        "\n",
        "Instead of using a RNN, now try using a LSTM model and compare both of them. Which of those performed better and why ?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bk4rLYHwI5VP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "782/782 [==============================] - 41s 51ms/step - loss: 0.3961 - accuracy: 0.8196 - val_loss: 0.3270 - val_accuracy: 0.8628\n",
            "Epoch 2/4\n",
            "782/782 [==============================] - 45s 58ms/step - loss: 0.2572 - accuracy: 0.8967 - val_loss: 0.3413 - val_accuracy: 0.8540\n",
            "Epoch 3/4\n",
            "782/782 [==============================] - 62s 80ms/step - loss: 0.2213 - accuracy: 0.9124 - val_loss: 0.3372 - val_accuracy: 0.8686\n",
            "Epoch 4/4\n",
            "782/782 [==============================] - 55s 71ms/step - loss: 0.1827 - accuracy: 0.9287 - val_loss: 0.3848 - val_accuracy: 0.8617\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fed21efe910>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lstm = Sequential()\n",
        "lstm.add(Embedding(vocabulary_size, 32, input_length=200) )\n",
        "lstm.add(LSTM(32) )\n",
        "lstm.add(Dense(1))\n",
        "lstm.add(Activation(\"sigmoid\"))\n",
        "\n",
        "lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 32\n",
        "num_epochs = 4\n",
        "\n",
        "lstm.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=num_epochs, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 8s 11ms/step - loss: 0.3848 - accuracy: 0.8617\n",
            "Loss: 0.38484108448028564 , accuracy:0.8616799712181091\n"
          ]
        }
      ],
      "source": [
        "scores_lstm = lstm.evaluate(X_test, y_test)\n",
        "print(f'Loss: {scores_lstm[0]} , accuracy:{scores_lstm[1]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBtRY9jmI5VQ"
      },
      "source": [
        "Perform Error analysis and explain using few examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "nrs2ylDaI5VR"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_length = np.array(list(map(len, X_test)))\n",
        "avg_length = np.average(test_length)\n",
        "test_long_idx = np.argwhere(test_length >400).reshape(-1)\n",
        "test_short_idx = np.argwhere(test_length <100).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_long = (X_test[test_long_idx])\n",
        "y_test_long = (y_test[test_long_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 6ms/step - loss: 0.3950 - accuracy: 0.8295\n",
            "Loss: 0.394974023103714 , accuracy:0.8294597864151001\n"
          ]
        }
      ],
      "source": [
        "X_test_long = sequence.pad_sequences(X_test_long, maxlen=200)\n",
        "scores_rnn = model.evaluate(X_test_long, y_test_long)\n",
        "print(f'Loss: {scores_rnn[0]} , accuracy:{scores_rnn[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 1s 10ms/step - loss: 0.4841 - accuracy: 0.8285\n",
            "Loss: 0.48413732647895813 , accuracy:0.8285176157951355\n"
          ]
        }
      ],
      "source": [
        "scores_lstm = lstm.evaluate(X_test_long, y_test_long)\n",
        "print(f'Loss: {scores_lstm[0]} , accuracy:{scores_lstm[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_short = (X_test[test_short_idx])\n",
        "y_test_short = (y_test[test_short_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 1s 6ms/step - loss: 0.3095 - accuracy: 0.8724\n",
            "Loss: 0.30948203802108765 , accuracy:0.8724265694618225\n"
          ]
        }
      ],
      "source": [
        "X_test_short = sequence.pad_sequences(X_test_short, maxlen=200)\n",
        "scores_rnn = model.evaluate(X_test_short, y_test_short)\n",
        "print(f'Loss: {scores_rnn[0]} , accuracy:{scores_rnn[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 1s 11ms/step - loss: 0.3184 - accuracy: 0.8738\n",
            "Loss: 0.31844764947891235 , accuracy:0.8737765550613403\n"
          ]
        }
      ],
      "source": [
        "scores_lstm = lstm.evaluate(X_test_short, y_test_short)\n",
        "print(f'Loss: {scores_lstm[0]} , accuracy:{scores_lstm[1]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
